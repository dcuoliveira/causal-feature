{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from data_mani.utils import merge_market_and_gtrends\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from prediction.util import new_r2, add_shift\n",
    "from prediction.util import get_selected_features\n",
    "from prediction.models import RandomForestWrapper\n",
    "\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from IPython.display import display, HTML\n",
    "from time import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ITER_SEARCH = 5\n",
    "N_SPLITS_SEARCH = 5\n",
    "N_JOBS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get selected features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of selected features: 2005\n"
     ]
    }
   ],
   "source": [
    "ticker_name =  \"AMZN US Equity\"\n",
    "fs_method = \"sfi\"\n",
    "out_folder = \"nasdaq\"\n",
    "\n",
    "select = get_selected_features(ticker_name=ticker_name,\n",
    "                               out_folder=out_folder,\n",
    "                               fs_method=fs_method)\n",
    "\n",
    "print(\"number of selected features:\", len(select))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get merged dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_path = \"data/crsp/{}/{}.csv\".format(out_folder,ticker_name)\n",
    "train, test = merge_market_and_gtrends(ticker_path, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2087, 183), (2087, 183))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.332412515993425"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(182*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add shift + Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "add shift: 100%|██████████| 182/182 [01:20<00:00,  2.25it/s]\n",
      "add shift: 100%|██████████| 182/182 [01:06<00:00,  2.72it/s]\n"
     ]
    }
   ],
   "source": [
    "words = train.drop(\"target_return\",1).columns.to_list()\n",
    "\n",
    "add_shift(merged_df=train, words=words, max_lag=20)\n",
    "train = train[[\"target_return\"] + select]\n",
    "train = train.fillna(0.0)\n",
    "\n",
    "add_shift(merged_df=test, words=words, max_lag=20)\n",
    "test = test[[\"target_return\"] + select]\n",
    "test = test.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2087, 2006), (2087, 2006))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "\n",
    "rf_wrapper = RandomForestWrapper()\n",
    "\n",
    "# model_name = \"random_forest\"\n",
    "# rf_params =  {\"max_features\":['auto', 'sqrt', 'log2'],\n",
    "#               \"min_samples_split\":sp_randint(2, 31),\n",
    "#               \"n_estimators\": sp_randint(2, 301),\n",
    "#               \"max_depth\": sp_randint(2, 20)}\n",
    "\n",
    "# RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_params_search(df,\n",
    "                        wrapper,\n",
    "                        n_iter,\n",
    "                        n_splits,\n",
    "                        n_jobs,\n",
    "                        target_name=\"target_return\"):\n",
    "    \"\"\"\n",
    "    Use the dataframe 'df' to search for the best\n",
    "    params for the model 'wrapper'.\n",
    "    \n",
    "    The CV split is performed using the TimeSeriesSplit\n",
    "    class\n",
    "\n",
    "    \"Empirical Asset Pricing via Machine\n",
    "    Learning\"\n",
    "\n",
    "    :param df: train data\n",
    "    :type df: pd.DataFrame\n",
    "    :param wrapper: predictive model\n",
    "    :type wrapper: sklearn model wrapper\n",
    "    :param n_iter: number of hyperparameter searchs\n",
    "    :type n_iter: int\n",
    "    :param n_splits: number of cross-validation splits\n",
    "    :type n_splits: int\n",
    "    :param target_name: name of the target column in 'df'\n",
    "    :type target_name: str\n",
    "    :return: R2 value\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "\n",
    "    X = df.drop(target_name,1).values\n",
    "    y = df[target_name].values\n",
    "\n",
    "    time_split = TimeSeriesSplit(n_splits=n_splits)\n",
    "    r2_scorer = make_scorer(new_r2)\n",
    "\n",
    "    model_search = RandomizedSearchCV(estimator=wrapper.ModelClass,\n",
    "                                      param_distributions=wrapper.param_grid,\n",
    "                                      n_iter=n_iter,\n",
    "                                      cv=time_split,\n",
    "                                      verbose=1,\n",
    "                                      n_jobs=n_jobs,\n",
    "                                      scoring=r2_scorer)\n",
    "\n",
    "    model_search = model_search.fit(X,y)\n",
    "\n",
    "    return model_search\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   6 out of   6 | elapsed:    5.8s finished\n"
     ]
    }
   ],
   "source": [
    "rf_wrapper = RandomForestWrapper()\n",
    "model_search =  hyper_params_search(df=train,\n",
    "                                    wrapper=rf_wrapper,\n",
    "                                    n_jobs=2,\n",
    "                                    n_iter=3,\n",
    "                                    n_splits=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004701568881441576"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = test.drop(\"target_return\",1).values\n",
    "y_test = test.target_return.values\n",
    "\n",
    "test_pred  = model_search.best_estimator_.predict(X_test)\n",
    "\n",
    "r2_test = new_r2(y_test, test_pred)\n",
    "r2_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 2,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_split': 30,\n",
       " 'n_estimators': 246}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_split = TimeSeriesSplit(n_splits=N_SPLITS)\n",
    "# r2_scorer = make_scorer(new_r2)\n",
    "# n_columns = X_train.shape[1]\n",
    "# rf_params =  {\"max_features\":list(range(1, int(np.sqrt(n_columns)+1))),\n",
    "#               \"n_estimators\": list(range(2, 60)),\n",
    "#               \"max_depth\": list(range(2, 21))}\n",
    "\n",
    "# rf_search = RandomizedSearchCV(estimator=RandomForestRegressor(),\n",
    "#                                param_distributions=rf_params,\n",
    "#                                n_iter=N_ITER,\n",
    "#                                cv=time_split,\n",
    "#                                verbose=1,\n",
    "#                                n_jobs=N_JOBS,\n",
    "#                                scoring=r2_scorer)\n",
    "\n",
    "# rf_search = rf_search.fit(X_train,y_train)\n",
    "# rf_train_pred  = rf_search.best_estimator_.predict(X_train)\n",
    "# rf_test_pred  = rf_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# r2_train = new_r2(y_train, rf_train_pred)\n",
    "# r2_test = new_r2(y_test, rf_test_pred)\n",
    "\n",
    "# results[\"train\"].append(r2_train)\n",
    "# results[\"test\"].append(r2_test)\n",
    "# results[\"model\"].append(\"Tunned Random Forest\")\n",
    "\n",
    "# result = pd.DataFrame(results).set_index(\"model\").sort_values(\"test\", ascending=False).to_html()\n",
    "# display(HTML(result))\n",
    "# print(rf_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model = RandomForestRegressor(**rf_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import TimeSeriesSplit\n",
    "# complete = pd.concat([train,test])\n",
    "# splits = int(complete.shape[0]/30)\n",
    "# tscv = TimeSeriesSplit(n_splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r2_hist = []\n",
    "\n",
    "\n",
    "# for train_index, test_index in tscv.split(complete):\n",
    "#     df_train = complete.iloc[train_index]\n",
    "#     df_test = complete.iloc[test_index]\n",
    "    \n",
    "#     model = RandomForestRegressor(**rf_search.best_params_)\n",
    "# #     print(df_train.shape)\n",
    "# #     print(df_test.shape)\n",
    "    \n",
    "    \n",
    "# #     X_train = train.drop(\"target_return\",1).values\n",
    "# #     y_train = train.target_return.values\n",
    "\n",
    "# #     X_test = test.drop(\"target_return\",1).values\n",
    "# #     y_test = test.target_return.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.loc[:, \"prediction\"] = rf_train_pred\n",
    "# test.loc[:, \"prediction\"] = rf_test_pred\n",
    "# both = [train[[\"target_return\", \"prediction\"]], test[[\"target_return\", \"prediction\"]]]\n",
    "# complete_forecast = pd.concat(both)\n",
    "# out_path_l = [\"results\", \"forecast\",fs_method,model_name,out_folder,ticker_name ]\n",
    "# out_path = os.path.join(*out_path_l)\n",
    "# out_path\n",
    "# complete_forecast.to_csv(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tempo = (time() - init) / 60\n",
    "# print(np.round(tempo,2), \"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.loc[:, \"type\"] = \"train\"\n",
    "# test.loc[:, \"type\"] = \"test\"\n",
    "\n",
    "# both = [train[[\"target_return\", \"prediction\", \"type\"]],\n",
    "#         test[[\"target_return\", \"prediction\", \"type\"]]]\n",
    "\n",
    "# complete_forecast = pd.concat(both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = complete_forecast[complete_forecast.type==\"test\"]\n",
    "# tt = new_r2(t.target_return.values, t.prediction.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tt, r2_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
