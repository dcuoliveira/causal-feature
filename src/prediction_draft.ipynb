{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from data_mani.utils import merge_market_and_gtrends\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from prediction.util import new_r2, add_shift\n",
    "from prediction.util import get_selected_features\n",
    "from prediction.models import RandomForestWrapper\n",
    "\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from IPython.display import display, HTML\n",
    "from time import time\n",
    "import os\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['0910150D US Equity', '1288652D US Equity',\n",
    "           '1831877D US Equity', 'ANDV US Equity',\n",
    "           'BCR US Equity', 'GR US Equity', 'HAR US Equity',\n",
    "           'HAS US Equity', 'HPC US Equity', 'MAT US Equity',\n",
    "           'NBL US Equity', 'TSS US Equity', 'TWX US Equity',\n",
    "           'TXU US Equity', 'WAMUQ US Equity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ITER_SEARCH = 5\n",
    "N_SPLITS_SEARCH = 5\n",
    "N_JOBS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get selected features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of selected features: 2219\n"
     ]
    }
   ],
   "source": [
    "ticker_name =  tickers[3]\n",
    "fs_method = \"fake\"\n",
    "out_folder = \"spx\"\n",
    "\n",
    "select = get_selected_features(ticker_name=ticker_name,\n",
    "                               out_folder=out_folder,\n",
    "                               fs_method=fs_method)\n",
    "\n",
    "print(\"number of selected features:\", len(select))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get merged dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1856, 183), (1856, 183))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker_path = \"data/index/{}/{}.csv\".format(out_folder,ticker_name)\n",
    "train, test = merge_market_and_gtrends(ticker_path, test_size=0.5)\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add shift + Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "add shift: 100%|██████████| 182/182 [00:48<00:00,  3.78it/s]\n",
      "add shift: 100%|██████████| 182/182 [00:40<00:00,  4.51it/s]\n"
     ]
    }
   ],
   "source": [
    "words = train.drop(\"target_return\",1).columns.to_list()\n",
    "\n",
    "add_shift(merged_df=train, words=words, max_lag=20)\n",
    "train = train[[\"target_return\"] + select]\n",
    "train = train.fillna(0.0)\n",
    "\n",
    "add_shift(merged_df=test, words=words, max_lag=20)\n",
    "test = test[[\"target_return\"] + select]\n",
    "test = test.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1856, 2220), (1856, 2220))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "\n",
    "rf_wrapper = RandomForestWrapper()\n",
    "\n",
    "# model_name = \"random_forest\"\n",
    "# rf_params =  {\"max_features\":['auto', 'sqrt', 'log2'],\n",
    "#               \"min_samples_split\":sp_randint(2, 31),\n",
    "#               \"n_estimators\": sp_randint(2, 301),\n",
    "#               \"max_depth\": sp_randint(2, 20)}\n",
    "\n",
    "# RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_params_search(df,\n",
    "                        wrapper,\n",
    "                        n_iter,\n",
    "                        n_splits,\n",
    "                        n_jobs,\n",
    "                        target_name=\"target_return\"):\n",
    "    \"\"\"\n",
    "    Use the dataframe 'df' to search for the best\n",
    "    params for the model 'wrapper'.\n",
    "    \n",
    "    The CV split is performed using the TimeSeriesSplit\n",
    "    class\n",
    "\n",
    "    \"Empirical Asset Pricing via Machine\n",
    "    Learning\"\n",
    "\n",
    "    :param df: train data\n",
    "    :type df: pd.DataFrame\n",
    "    :param wrapper: predictive model\n",
    "    :type wrapper: sklearn model wrapper\n",
    "    :param n_iter: number of hyperparameter searchs\n",
    "    :type n_iter: int\n",
    "    :param n_splits: number of cross-validation splits\n",
    "    :type n_splits: int\n",
    "    :param target_name: name of the target column in 'df'\n",
    "    :type target_name: str\n",
    "    :return: R2 value\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "\n",
    "    X = df.drop(target_name,1).values\n",
    "    y = df[target_name].values\n",
    "\n",
    "    time_split = TimeSeriesSplit(n_splits=n_splits)\n",
    "    r2_scorer = make_scorer(new_r2)\n",
    "\n",
    "    model_search = RandomizedSearchCV(estimator=wrapper.ModelClass,\n",
    "                                      param_distributions=wrapper.param_grid,\n",
    "                                      n_iter=n_iter,\n",
    "                                      cv=time_split,\n",
    "                                      verbose=1,\n",
    "                                      n_jobs=n_jobs,\n",
    "                                      scoring=r2_scorer)\n",
    "\n",
    "    model_search = model_search.fit(X,y)\n",
    "\n",
    "    return model_search\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   6 out of   6 | elapsed:   59.0s finished\n"
     ]
    }
   ],
   "source": [
    "rf_wrapper = RandomForestWrapper()\n",
    "model_search =  hyper_params_search(df=train,\n",
    "                                    wrapper=rf_wrapper,\n",
    "                                    n_jobs=2,\n",
    "                                    n_iter=3,\n",
    "                                    n_splits=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_return</th>\n",
       "      <th>home_20</th>\n",
       "      <th>money_14</th>\n",
       "      <th>dow_jones_2</th>\n",
       "      <th>tourism_20</th>\n",
       "      <th>carolina_14</th>\n",
       "      <th>sell_20</th>\n",
       "      <th>return_13</th>\n",
       "      <th>present_17</th>\n",
       "      <th>loss_19</th>\n",
       "      <th>...</th>\n",
       "      <th>virginia_8</th>\n",
       "      <th>community_6</th>\n",
       "      <th>cash_4</th>\n",
       "      <th>return_12</th>\n",
       "      <th>BUY_AND_HOLD_2</th>\n",
       "      <th>companies_11</th>\n",
       "      <th>elections_4</th>\n",
       "      <th>democratic_1</th>\n",
       "      <th>gold_17</th>\n",
       "      <th>greed_14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-01-02</th>\n",
       "      <td>0.016472</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-05</th>\n",
       "      <td>0.039838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-06</th>\n",
       "      <td>-0.014935</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-07</th>\n",
       "      <td>-0.017798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-01-08</th>\n",
       "      <td>-0.026846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-05-10</th>\n",
       "      <td>0.000388</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-05-11</th>\n",
       "      <td>-0.047287</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-05-12</th>\n",
       "      <td>-0.031733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-05-13</th>\n",
       "      <td>-0.015546</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-05-16</th>\n",
       "      <td>0.000854</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1856 rows × 2220 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            target_return  home_20  money_14  dow_jones_2  tourism_20  \\\n",
       "date                                                                    \n",
       "2004-01-02       0.016472      0.0       0.0          0.0         0.0   \n",
       "2004-01-05       0.039838      0.0       0.0          0.0         0.0   \n",
       "2004-01-06      -0.014935      0.0       0.0          2.0         0.0   \n",
       "2004-01-07      -0.017798      0.0       0.0          1.0         0.0   \n",
       "2004-01-08      -0.026846      0.0       0.0          0.0         0.0   \n",
       "...                   ...      ...       ...          ...         ...   \n",
       "2011-05-10       0.000388     -1.0      -1.0          0.0         0.0   \n",
       "2011-05-11      -0.047287     -2.0       0.0          0.0         0.0   \n",
       "2011-05-12      -0.031733      0.0       0.0          0.0         0.0   \n",
       "2011-05-13      -0.015546     -1.0       1.0          1.0         0.0   \n",
       "2011-05-16       0.000854      0.0       0.0         -1.0         0.0   \n",
       "\n",
       "            carolina_14  sell_20  return_13  present_17  loss_19  ...  \\\n",
       "date                                                              ...   \n",
       "2004-01-02          0.0      0.0        0.0         0.0      0.0  ...   \n",
       "2004-01-05          0.0      0.0        0.0         0.0      0.0  ...   \n",
       "2004-01-06          0.0      0.0        0.0         0.0      0.0  ...   \n",
       "2004-01-07          0.0      0.0        0.0         0.0      0.0  ...   \n",
       "2004-01-08          0.0      0.0        0.0         0.0      0.0  ...   \n",
       "...                 ...      ...        ...         ...      ...  ...   \n",
       "2011-05-10         -2.0      0.0       -1.0         0.0      0.0  ...   \n",
       "2011-05-11         -1.0      0.0        0.0         0.0      0.0  ...   \n",
       "2011-05-12         -1.0      0.0        0.0         0.0     -1.0  ...   \n",
       "2011-05-13          2.0      0.0        0.0         0.0      0.0  ...   \n",
       "2011-05-16         -1.0      0.0        0.0         0.0      0.0  ...   \n",
       "\n",
       "            virginia_8  community_6  cash_4  return_12  BUY_AND_HOLD_2  \\\n",
       "date                                                                     \n",
       "2004-01-02         0.0          0.0     0.0        0.0             0.0   \n",
       "2004-01-05         0.0          0.0     0.0        0.0             0.0   \n",
       "2004-01-06         0.0          0.0     0.0        0.0             0.0   \n",
       "2004-01-07         0.0          0.0     0.0        0.0            -1.0   \n",
       "2004-01-08         0.0          0.0    -1.0        0.0             0.0   \n",
       "...                ...          ...     ...        ...             ...   \n",
       "2011-05-10         1.0          4.0     0.0        0.0             0.0   \n",
       "2011-05-11        -2.0          2.0     0.0        0.0             0.0   \n",
       "2011-05-12         1.0          0.0     0.0        0.0             0.0   \n",
       "2011-05-13         0.0         -2.0     1.0        0.0             0.0   \n",
       "2011-05-16         0.0          0.0     0.0        0.0             0.0   \n",
       "\n",
       "            companies_11  elections_4  democratic_1  gold_17  greed_14  \n",
       "date                                                                    \n",
       "2004-01-02           0.0          0.0           0.0      0.0       0.0  \n",
       "2004-01-05           0.0          0.0           0.0      0.0       0.0  \n",
       "2004-01-06           0.0          0.0           1.0      0.0       0.0  \n",
       "2004-01-07           0.0          0.0          -2.0      0.0       0.0  \n",
       "2004-01-08           0.0          1.0           0.0      0.0       0.0  \n",
       "...                  ...          ...           ...      ...       ...  \n",
       "2011-05-10           2.0         -1.0           0.0      0.0       0.0  \n",
       "2011-05-11           1.0          0.0           0.0      1.0       0.0  \n",
       "2011-05-12          -1.0         -1.0           1.0      1.0       0.0  \n",
       "2011-05-13           0.0          1.0          -1.0      0.0       0.0  \n",
       "2011-05-16          -1.0         -1.0           0.0      0.0       0.0  \n",
       "\n",
       "[1856 rows x 2220 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   6 out of   6 | elapsed:    7.7s finished\n"
     ]
    }
   ],
   "source": [
    "model_search =  hyper_params_search(df=train[\"2006\"],\n",
    "                                    wrapper=rf_wrapper,\n",
    "                                    n_jobs=2,\n",
    "                                    n_iter=3,\n",
    "                                    n_splits=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=TimeSeriesSplit(max_train_size=None, n_splits=2),\n",
       "                   estimator=RandomForestRegressor(), n_iter=3, n_jobs=2,\n",
       "                   param_distributions={'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7ff2e82353a0>,\n",
       "                                        'max_features': ['auto', 'sqrt',\n",
       "                                                         'log2'],\n",
       "                                        'min_samples_split': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7ff2a3497880>,\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7ff2a3498c10>},\n",
       "                   scoring=make_scorer(new_r2), verbose=1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.06225914585345893"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = test.drop(\"target_return\",1).values\n",
    "y_test = test.target_return.values\n",
    "\n",
    "test_pred  = model_search.best_estimator_.predict(X_test)\n",
    "\n",
    "r2_test = new_r2(y_test, test_pred)\n",
    "r2_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.023994168654803527"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train.drop(\"target_return\",1).values\n",
    "y_train = train.target_return.values\n",
    "pred  = model_search.best_estimator_.predict(X_train)\n",
    "\n",
    "r2_ = new_r2(y_train, pred)\n",
    "r2_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_split': 16,\n",
       " 'n_estimators': 252}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete = pd.concat([train,test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    3.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    3.7s finished\n",
      " 25%|██▌       | 1/4 [00:07<00:23,  7.68s/it][Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   17.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   17.5s finished\n",
      " 50%|█████     | 2/4 [00:49<00:35, 17.93s/it][Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    4.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    4.2s finished\n",
      " 75%|███████▌  | 3/4 [00:59<00:15, 15.41s/it][Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   46.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   46.2s finished\n",
      "100%|██████████| 4/4 [02:57<00:00, 44.27s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "all_preds = []\n",
    "\n",
    "years = list(set(complete.index.map(lambda x: x.year)))\n",
    "years.sort()\n",
    "years = years[:-1]\n",
    "years = years[:4]\n",
    "\n",
    "for y in tqdm(years):\n",
    "    train_ys = complete[:str(y)]\n",
    "    test_ys = complete[str(y+1)]\n",
    "    rf_wrapper = RandomForestWrapper()\n",
    "    model_search =  hyper_params_search(df=train_ys,\n",
    "                                        wrapper=rf_wrapper,\n",
    "                                        n_jobs=2,\n",
    "                                        n_iter=1,\n",
    "                                        n_splits=2)\n",
    "    X_test = test_ys.drop(\"target_return\",1).values\n",
    "    y_test = test_ys.target_return.values\n",
    "    test_pred  = model_search.best_estimator_.predict(X_test)\n",
    "    dict_ = {\"date\": test_ys.index,\n",
    "             \"return\":y_test,\n",
    "             \"prediction\":test_pred}\n",
    "    result = pd.DataFrame(dict_)\n",
    "    all_preds.append(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.008211028150391986"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat(all_preds)\n",
    "r2_ = new_r2(df[\"return\"].values, df[\"prediction\"].values)\n",
    "r2_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ANDV US Equity'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
